{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fad15a600d8a4b8a0e8a23fef765b8b578b0596"
   },
   "source": [
    "# Introduction\n",
    "I had previously written a short kernel to practice Python. My \"native language\" is R, but the benefits of using Python are too great to ignore. In this notebook, I revist the same dataset but attempt several additional techniques, including: \n",
    "1. Pre-process with object-oriented programming\n",
    "2. Create Pipeline\n",
    "    * using custom transformers\n",
    "    * using decorators and a \"general pipleline class\" \n",
    "3. Use partial dependency plots\n",
    "4. running multiple aglorithms through a pipeline\n",
    "\n",
    "The individual elements could be the subject af a kernel all to themselves, but I am choosing to make each occupy a section within this Kernel. I hope this helps you on your python journey! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20a145f3146cd2976f0ab5a8c58ac148170b9710"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from subprocess import check_output\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_regression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import reciprocal, uniform\n",
    "from pdpbox import pdp, info_plots\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "#import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c27632dd1c175006c86049bba665ae304d5068d"
   },
   "source": [
    "# Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c9977d2d8d7ae50e2a5129cf3f368e87e6cb6f9"
   },
   "source": [
    "Below is a (nested?) dictionary which contains specific values for each column. This was initially performed by another user on Kaggle -- if someone happens to know who made these dicionaries initially then I will edit this notebook and provide proper attribution.  My contribution was coalesce all of the individual dictionaries into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "de20ffb3ea9c86109148b3b202ce0e48f516436f"
   },
   "outputs": [],
   "source": [
    "replacement_dict = {\"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\", 7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"},\n",
    "            \"SaleCondition\" : {\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1},\n",
    "            \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "            \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "            \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "            \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "            \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "            \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n",
    "            \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n",
    "            \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "            \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "            \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4},\n",
    "            \"OverallQual\" : {1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                           4 : 2, 5 : 2, 6 : 2, # average\n",
    "                           7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                          },\n",
    "            \"OverallCond\" : {1 : 1, 2 : 1, 3 : 1, # bad\n",
    "                                      4 : 2, 5 : 2, 6 : 2, # average\n",
    "                                      7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n",
    "                                     },\n",
    "    \"ModExterCond\" : {1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  },\n",
    "    \"ModExterQual\" : {1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  },\n",
    "    \"ModFunctional\" : {1 : 1, 2 : 1, # bad\n",
    "                                                     3 : 2, 4 : 2, # major\n",
    "                                                     5 : 3, 6 : 3, 7 : 3, # minor\n",
    "                                                     8 : 4 # typical\n",
    "                                                    },\n",
    "    \"ModKitchenQual\" : {1 : 1, # bad\n",
    "                                                       2 : 1, 3 : 1, # average\n",
    "                                                       4 : 2, 5 : 2 # good\n",
    "                                                      },\n",
    "    \"ModHeatingQC\" : {1 : 1, # bad\n",
    "                                                   2 : 1, 3 : 1, # average\n",
    "                                                   4 : 2, 5 : 2 # good\n",
    "                                                  }   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1b1c6122c57550ddaad078e394524e7c8bf34a0"
   },
   "source": [
    "# 1. Pre-process with Object Oriented Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "319646cf9658217dd5c3a507168835e2451d7be4"
   },
   "source": [
    "I have learned that there are many benefits to using OOP with Python. It makes code more readable, reproducible, testable, etc. For this section, I create a python class specifically for this competition to handle the \"pre-processing\" of the data. What I mean by \"pre-processing\" is making the training and testing sets equivalent in form. This class contains functions to: \n",
    "1. Load the training and testing data\n",
    "2. Generate a \"submission\" dataframe\n",
    "3. Use the above dictionary to replace vlalues\n",
    "4. Create new columns by:\n",
    "    * multiplication\n",
    "    * addition\n",
    "    * hardcoding\n",
    "5. Log transforming the response\n",
    "6. Removing categories that do not show up in Test (to allow for one-hot-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e797274dd9e4df5c89f26f4c6614917a15308b4f"
   },
   "outputs": [],
   "source": [
    "# Define Class\n",
    "class HousingPricesRegression():\n",
    "    # class initialization\n",
    "    def __init__(self, train_path, test_path):\n",
    "        self.train = pd.read_csv(train_path)\n",
    "        self.test = pd.read_csv(test_path)\n",
    "        self.submission = pd.DataFrame()\n",
    "    def gen_submission_file(self, id_col):\n",
    "        self.submission[id_col] = self.test[id_col]\n",
    "        self.test.drop([id_col], axis = 1, inplace=True)\n",
    "    # replace information within columns\n",
    "    def replace_values(self, replace_dict):\n",
    "        # Find name (top level key)\n",
    "        key_name = str(*replace_dict)\n",
    "        true_index = np.where(self.train.columns.isin([key_name]))\n",
    "        col_name = list(self.train.columns[true_index])\n",
    "        if len(col_name) == 0:\n",
    "            # Option 1: Dictionary refers to a key that doesn't exist. Create one!\n",
    "            orig_name = key_name[3:]\n",
    "            self.train[key_name] = self.train[orig_name].map(replace_dict[key_name])\n",
    "            self.test[key_name] = self.test[orig_name].map(replace_dict[key_name])\n",
    "        else:\n",
    "            # Option 2: Dictionary refers to a key that does exist. Modify! \n",
    "            # Take 'ModExterCond' and find the original (\"ExterCond\")\n",
    "            self.train[key_name] = self.train[key_name].map(replace_dict[key_name])\n",
    "            self.test[key_name] = self.test[key_name].map(replace_dict[key_name])\n",
    "    # Take Logarithm of Response\n",
    "    def create_response(self, response):\n",
    "        self.price_labels = np.log(self.train[response].copy() + 1)\n",
    "        # drop original to avoid confusion\n",
    "        self.train.drop([response], axis=1, inplace = True)  \n",
    "    # Remove categories \n",
    "    def remove_categories(self, cat_cols):\n",
    "        for i in cat_cols:\n",
    "            trn = self.train[i].astype('category')\n",
    "            trn = trn.cat.categories\n",
    "            tst = self.test[i].astype('category')\n",
    "            tst = tst.cat.categories\n",
    "            # Find that which is in test which is not in train\n",
    "            unique_values_train = list(set(trn) - set(tst))\n",
    "            # Check \n",
    "            # If no difference, print\n",
    "            if len(unique_values_train)==0:\n",
    "                print(\"No Differnence for {}\".format(i))\n",
    "            else:\n",
    "                # If there is a differnce, change to NA in test for later imputation\n",
    "                for j in unique_values_train:\n",
    "                    to_replace_index = self.train.loc[self.train[i]==j,i].index\n",
    "                    self.train.loc[to_replace_index,i] = float('NaN')\n",
    "                    self.train[i] = self.train[i].cat.remove_categories(j)\n",
    "                    print(\"{} removed from {} in train\".format(j,i))\n",
    "    # Set the category type \n",
    "    def make_category(self, cat_cols):\n",
    "        self.train[cat_cols] = self.train[cat_cols].astype('category')\n",
    "        self.test[cat_cols] = self.test[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c7cd3b831c86b1d5bc7d462ff4667aa396ad86b"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c95568a9daaf3929f3a01acc609126a33224e3d9"
   },
   "outputs": [],
   "source": [
    "# Define Paths\n",
    "file_path = '/home/gopherguy14/PYTHON_PROJECTS/Housing_Prices/'\n",
    "train_path = str(file_path) + str('train.csv')\n",
    "test_path = str(file_path) + str('test.csv')\n",
    "submission_path = str(file_path) + str()\n",
    "\n",
    "# Instantiate model object\n",
    "hprObject = HousingPricesRegression(train_path, test_path)\n",
    "\n",
    "# Generate submission file\n",
    "hprObject.gen_submission_file(id_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec7b7593724c1c793f467bd3be78fbe89e3c509c"
   },
   "source": [
    "#### Call Replacement Method\n",
    "\n",
    "It's possible to get the key-names of a dictionary using `*dict`. This block of code loops through `replacement_dict`, essentially creating a subset dictionary. This subset is then passed to the `replace_values()` method, which in turn grabs the top level key (the column name) and attempts to find all of the levels to replace, which is accomplished by `.map()`. Note that the train and test data are pandas dataframes at this point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "dee1661cdf3ed6fb93269b0466dc33f42f5338b6"
   },
   "outputs": [],
   "source": [
    "# Replace features - multiple columns\n",
    "for key, values in replacement_dict.items():\n",
    "    temp_dict = {}\n",
    "    temp_dict[key] = replacement_dict[key] \n",
    "    hprObject.replace_values(temp_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ffe40578d6389a7e3b936071f9b70b35f6e17443"
   },
   "source": [
    "#### Create Response\n",
    "This creates a single column dataframe called `price_labels` that is a copy of that in train, except log-transformed. The corresponding column in the train dataframe is also dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4fb26d688b4bd86af2e3b20b9dfb9f9abf036cc8"
   },
   "outputs": [],
   "source": [
    "# This takes the log of the sales price\n",
    "hprObject.create_response(response=\"SalePrice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3dd451a99239b17fd5ec80168b44975df67a242"
   },
   "source": [
    "#### Equivocate Training and Test Sets\n",
    "I had trouble with this for a while. Apparently, there are 'levels' in a given column in train that do not exist in test. For some reason, I have a problem with one-hot encoding if I do *not* reconcile this. What I do now is simply make that particular 'cell' (a specific row in a specific column) blank. *I do not delete the row*. Later in the kernel I impute for blanks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "c9550b2e545818a66b43ee5087ab03906b379d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Differnence for LandContour\n",
      "No Differnence for BsmtFinType1\n",
      "Other removed from Exterior2nd in train\n",
      "No Differnence for MoSold\n",
      "No Differnence for Neighborhood\n",
      "No Differnence for SaleType\n",
      "No Differnence for GarageType\n",
      "No Differnence for GarageCond\n",
      "No Differnence for Fence\n",
      "No Differnence for BsmtQual\n",
      "No Differnence for BsmtCond\n",
      "Membran removed from RoofMatl in train\n",
      "ClyTile removed from RoofMatl in train\n",
      "Roll removed from RoofMatl in train\n",
      "Metal removed from RoofMatl in train\n",
      "No Differnence for LotConfig\n",
      "Fa removed from PoolQC in train\n",
      "No Differnence for BsmtExposure\n",
      "No Differnence for Foundation\n",
      "TenC removed from MiscFeature in train\n",
      "Mix removed from Electrical in train\n",
      "2.5Fin removed from HouseStyle in train\n",
      "No Differnence for Alley\n",
      "No Differnence for GarageFinish\n",
      "No Differnence for RoofStyle\n",
      "OthW removed from Heating in train\n",
      "Floor removed from Heating in train\n",
      "No Differnence for MasVnrType\n",
      "No Differnence for CentralAir\n",
      "No Differnence for Condition1\n",
      "Ex removed from GarageQual in train\n",
      "RRAn removed from Condition2 in train\n",
      "RRNn removed from Condition2 in train\n",
      "RRAe removed from Condition2 in train\n",
      "No Differnence for MSZoning\n",
      "No Differnence for FireplaceQu\n",
      "Stone removed from Exterior1st in train\n",
      "ImStucc removed from Exterior1st in train\n",
      "No Differnence for BsmtFinType2\n",
      "No Differnence for BldgType\n"
     ]
    }
   ],
   "source": [
    "## Create list of numerical and categorical attributes\n",
    "num_cols = hprObject.test._get_numeric_data().columns\n",
    "cat_cols = list(set(hprObject.test.columns) - set(num_cols))\n",
    "num_cols = list(num_cols)\n",
    "\n",
    "## Need to move this to a class method or something\n",
    "hprObject.make_category(cat_cols)\n",
    "\n",
    "# Replace unique levels in test with NaN to be imputed later\n",
    "hprObject.remove_categories(cat_cols)\n",
    "\n",
    "## Make sure that the training data only reflects the columns in the testing data \n",
    "names_in_test = list(hprObject.test)\n",
    "hprObject.train = hprObject.train[names_in_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Column Names ##\n",
    "kitchen_col = ['KitchenAbvGr', 'KitchenQual']\n",
    "grade_col = ['OverallQual', 'OverallCond']\n",
    "exter_cond = ['ExterQual','ExterCond']\n",
    "add_area = ['GrLivArea','TotalBsmtSF']\n",
    "add_floor = ['1stFlrSF', '2ndFlrSF']\n",
    "add_porch = ['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']\n",
    "count_bath = ['BsmtFullBath','FullBath','BsmtHalfBath','HalfBath']\n",
    "\n",
    "feature_num = kitchen_col + grade_col + exter_cond + add_area + add_floor + add_porch + count_bath \n",
    "other_num_cols = list(set(num_cols) - set(feature_num))\n",
    "\n",
    "## Column Transformers ##\n",
    "feature_engineering = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('multi_kitchen', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), kitchen_col),\n",
    "        ('multi_grade', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), grade_col),\n",
    "        ('multi_exter', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), exter_cond),\n",
    "        ('add_total_SF', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), add_area),\n",
    "        ('add_floor_SF', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), add_floor),\n",
    "        ('add_porch_SF', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), add_porch),\n",
    "        ('count_baths', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), count_bath)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "other_numerical = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('impute_other', SimpleImputer(strategy=\"median\"), other_num_cols),\n",
    "        ('scale_other', StandardScaler(), other_num_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "categorical = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('impute_cats', SimpleImputer(strategy=\"most_frequent\"), cat_cols),\n",
    "        \n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "other_missing = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('other_missing', MissingIndicator(features='all'), other_num_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "category_missing = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cat_missing', MissingIndicator(features='all'), cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "## Pipelines ## \n",
    "step1 = Pipeline([\n",
    "    ('feat_eng', feature_engineering),\n",
    "    ('impute_feats', SimpleImputer(strategy=\"median\")),\n",
    "    ('scale_feats', StandardScaler())\n",
    "])\n",
    "\n",
    "step2 = Pipeline([\n",
    "    ('other_nums', other_numerical),\n",
    "    ('impute_nums', SimpleImputer(strategy=\"median\")),\n",
    "    ('scale_nums', StandardScaler())\n",
    "])\n",
    "\n",
    "step3 = Pipeline([\n",
    "    ('categ', categorical),\n",
    "    ('encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "        \n",
    "unify = FeatureUnion([\n",
    "    ('new_features', step1 ),\n",
    "    ('numeric_scale', step2), \n",
    "    ('categoric_encode', step3),\n",
    "    ('num_missing_indicator', other_missing),\n",
    "    ('cat_missing_indicator', category_missing)\n",
    "])\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('finally', unify)\n",
    "])\n",
    "\n",
    "## Just checking\n",
    "#f = final_pipeline.fit_transform(hprObject.train)\n",
    "#f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train into train and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(hprObject.train, hprObject.price_labels, test_size = 0.2)\n",
    "\n",
    "# list names of regressors\n",
    "names = [\n",
    "         \"Support-Vector Regressor\",\n",
    "         \"Random Forest Regressor\"\n",
    "        ]\n",
    "\n",
    "regressors = [\n",
    "    SVR(),\n",
    "    RandomForestRegressor()\n",
    "]\n",
    "\n",
    "parameters = [\n",
    "                  {\n",
    "                      'reg__C': (reciprocal(0.001, 0.1)), \n",
    "                      'reg__gamma': (uniform(1, 10))\n",
    "                  },\n",
    "                  {\n",
    "                      'reg__max_depth': (5,10,15)\n",
    "                  }\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] reg__C=0.005611516415334503, reg__gamma=10.50714306409916 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg__C=0.005611516415334503, reg__gamma=10.50714306409916, total=   0.5s\n",
      "[CV] reg__C=0.005611516415334503, reg__gamma=10.50714306409916 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  reg__C=0.005611516415334503, reg__gamma=10.50714306409916, total=   0.4s\n",
      "[CV] reg__C=0.005611516415334503, reg__gamma=10.50714306409916 .......\n",
      "[CV]  reg__C=0.005611516415334503, reg__gamma=10.50714306409916, total=   0.5s\n",
      "[CV] reg__C=0.029106359131330688, reg__gamma=6.986584841970366 .......\n",
      "[CV]  reg__C=0.029106359131330688, reg__gamma=6.986584841970366, total=   0.4s\n",
      "[CV] reg__C=0.029106359131330688, reg__gamma=6.986584841970366 .......\n",
      "[CV]  reg__C=0.029106359131330688, reg__gamma=6.986584841970366, total=   0.5s\n",
      "[CV] reg__C=0.029106359131330688, reg__gamma=6.986584841970366 .......\n",
      "[CV]  reg__C=0.029106359131330688, reg__gamma=6.986584841970366, total=   0.5s\n",
      "[CV] reg__C=0.0020513382630874496, reg__gamma=2.5599452033620267 .....\n",
      "[CV]  reg__C=0.0020513382630874496, reg__gamma=2.5599452033620267, total=   0.4s\n",
      "[CV] reg__C=0.0020513382630874496, reg__gamma=2.5599452033620267 .....\n",
      "[CV]  reg__C=0.0020513382630874496, reg__gamma=2.5599452033620267, total=   0.5s\n",
      "[CV] reg__C=0.0020513382630874496, reg__gamma=2.5599452033620267 .....\n",
      "[CV]  reg__C=0.0020513382630874496, reg__gamma=2.5599452033620267, total=   0.5s\n",
      "[CV] reg__C=0.0013066739238053278, reg__gamma=9.661761457749352 ......\n",
      "[CV]  reg__C=0.0013066739238053278, reg__gamma=9.661761457749352, total=   0.4s\n",
      "[CV] reg__C=0.0013066739238053278, reg__gamma=9.661761457749352 ......\n",
      "[CV]  reg__C=0.0013066739238053278, reg__gamma=9.661761457749352, total=   0.4s\n",
      "[CV] reg__C=0.0013066739238053278, reg__gamma=9.661761457749352 ......\n",
      "[CV]  reg__C=0.0013066739238053278, reg__gamma=9.661761457749352, total=   0.5s\n",
      "[CV] reg__C=0.01593052261624101, reg__gamma=8.080725777960454 ........\n",
      "[CV]  reg__C=0.01593052261624101, reg__gamma=8.080725777960454, total=   0.5s\n",
      "[CV] reg__C=0.01593052261624101, reg__gamma=8.080725777960454 ........\n",
      "[CV]  reg__C=0.01593052261624101, reg__gamma=8.080725777960454, total=   0.4s\n",
      "[CV] reg__C=0.01593052261624101, reg__gamma=8.080725777960454 ........\n",
      "[CV]  reg__C=0.01593052261624101, reg__gamma=8.080725777960454, total=   0.4s\n",
      "[CV] reg__C=0.0010994335574766197, reg__gamma=10.699098521619943 .....\n",
      "[CV]  reg__C=0.0010994335574766197, reg__gamma=10.699098521619943, total=   0.4s\n",
      "[CV] reg__C=0.0010994335574766197, reg__gamma=10.699098521619943 .....\n",
      "[CV]  reg__C=0.0010994335574766197, reg__gamma=10.699098521619943, total=   0.5s\n",
      "[CV] reg__C=0.0010994335574766197, reg__gamma=10.699098521619943 .....\n",
      "[CV]  reg__C=0.0010994335574766197, reg__gamma=10.699098521619943, total=   0.5s\n",
      "[CV] reg__C=0.046225890010208284, reg__gamma=3.1233911067827616 ......\n",
      "[CV]  reg__C=0.046225890010208284, reg__gamma=3.1233911067827616, total=   0.5s\n",
      "[CV] reg__C=0.046225890010208284, reg__gamma=3.1233911067827616 ......\n",
      "[CV]  reg__C=0.046225890010208284, reg__gamma=3.1233911067827616, total=   0.5s\n",
      "[CV] reg__C=0.046225890010208284, reg__gamma=3.1233911067827616 ......\n",
      "[CV]  reg__C=0.046225890010208284, reg__gamma=3.1233911067827616, total=   0.5s\n",
      "[CV] reg__C=0.002310201887845293, reg__gamma=2.834045098534338 .......\n",
      "[CV]  reg__C=0.002310201887845293, reg__gamma=2.834045098534338, total=   0.5s\n",
      "[CV] reg__C=0.002310201887845293, reg__gamma=2.834045098534338 .......\n",
      "[CV]  reg__C=0.002310201887845293, reg__gamma=2.834045098534338, total=   0.5s\n",
      "[CV] reg__C=0.002310201887845293, reg__gamma=2.834045098534338 .......\n",
      "[CV]  reg__C=0.002310201887845293, reg__gamma=2.834045098534338, total=   0.5s\n",
      "[CV] reg__C=0.004059611610484304, reg__gamma=6.247564316322379 .......\n",
      "[CV]  reg__C=0.004059611610484304, reg__gamma=6.247564316322379, total=   0.5s\n",
      "[CV] reg__C=0.004059611610484304, reg__gamma=6.247564316322379 .......\n",
      "[CV]  reg__C=0.004059611610484304, reg__gamma=6.247564316322379, total=   0.5s\n",
      "[CV] reg__C=0.004059611610484304, reg__gamma=6.247564316322379 .......\n",
      "[CV]  reg__C=0.004059611610484304, reg__gamma=6.247564316322379, total=   0.5s\n",
      "[CV] reg__C=0.0073095398359129095, reg__gamma=3.9122914019804194 .....\n",
      "[CV]  reg__C=0.0073095398359129095, reg__gamma=3.9122914019804194, total=   0.5s\n",
      "[CV] reg__C=0.0073095398359129095, reg__gamma=3.9122914019804194 .....\n",
      "[CV]  reg__C=0.0073095398359129095, reg__gamma=3.9122914019804194, total=   0.5s\n",
      "[CV] reg__C=0.0073095398359129095, reg__gamma=3.9122914019804194 .....\n",
      "[CV]  reg__C=0.0073095398359129095, reg__gamma=3.9122914019804194, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   21.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support-Vector Regressor score: -0.1555474469376055\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] reg__max_depth=5 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. reg__max_depth=5, total=   0.3s\n",
      "[CV] reg__max_depth=5 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. reg__max_depth=5, total=   0.3s\n",
      "[CV] reg__max_depth=5 ................................................\n",
      "[CV] ................................. reg__max_depth=5, total=   0.3s\n",
      "[CV] reg__max_depth=10 ...............................................\n",
      "[CV] ................................ reg__max_depth=10, total=   0.7s\n",
      "[CV] reg__max_depth=10 ...............................................\n",
      "[CV] ................................ reg__max_depth=10, total=   0.7s\n",
      "[CV] reg__max_depth=10 ...............................................\n",
      "[CV] ................................ reg__max_depth=10, total=   0.7s\n",
      "[CV] reg__max_depth=15 ...............................................\n",
      "[CV] ................................ reg__max_depth=15, total=   0.9s\n",
      "[CV] reg__max_depth=15 ...............................................\n",
      "[CV] ................................ reg__max_depth=15, total=   0.9s\n",
      "[CV] reg__max_depth=15 ...............................................\n",
      "[CV] ................................ reg__max_depth=15, total=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor score: -0.02450339621788411\n"
     ]
    }
   ],
   "source": [
    "model_list = {}\n",
    "for name, regressor, params in zip(names, regressors, parameters):\n",
    "    reg_pipe = Pipeline([\n",
    "        ('pipeline', final_pipeline),\n",
    "        ('reg', regressor),\n",
    "    ])\n",
    "    rs_reg = RandomizedSearchCV(reg_pipe, params, n_iter=10, verbose=2, random_state=42, scoring='neg_mean_squared_error')\n",
    "    regres = rs_reg.fit(X_train, y_train)\n",
    "    score = regres.score(X_val, y_val)\n",
    "    print(\"{} score: {}\".format(name, score))\n",
    "    model_list[name] = regres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg__C': 0.046225890010208284, 'reg__gamma': 3.1233911067827616}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list['Support-Vector Regressor'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg__max_depth': 10}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list['Random Forest Regressor'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "555afb474fdea96cfecaba1d5d48ef1adf35e6bc"
   },
   "outputs": [],
   "source": [
    "# Fit with optimized parameters\n",
    "svr_pipe = Pipeline([\n",
    "        ('pipeline', final_pipeline),\n",
    "        ('svr', SVR(\n",
    "            gamma = model_list['Support-Vector Regressor'].best_params_[\"reg__gamma\"], \n",
    "            C = model_list['Support-Vector Regressor'].best_params_[\"reg__C\"]\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('pipeline', final_pipeline),\n",
    "    ('rf', RandomForestRegressor(max_depth = model_list['Random Forest Regressor'].best_params_[\"reg__max_depth\"]))\n",
    "])\n",
    "\n",
    "svr_model = svr_pipe.fit(X_train, y_train)\n",
    "rf_model = rf_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('other_nums',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "            transformer_weights=None,\n",
       "            transformers=[('impute_other', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='median', verbose=0), ['LotShape', 'PoolArea', 'MiscVal', 'YrSold', 'WoodDeckSF', 'PavedDrive', 'Functional', 'TotRmsAbvGrd', 'MSSubClass', 'GarageArea', 'LandSlope', 'GarageYrBlt', 'LotArea'...replaces', 'HeatingQC', 'BedroomAbvGr', 'MasVnrArea', 'LotFrontage', 'ModFunctional', 'Utilities'])])),\n",
       "  ('impute_nums', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='median', verbose=0)),\n",
       "  ('scale_nums', StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'other_nums': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "          transformer_weights=None,\n",
       "          transformers=[('impute_other', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "        strategy='median', verbose=0), ['LotShape', 'PoolArea', 'MiscVal', 'YrSold', 'WoodDeckSF', 'PavedDrive', 'Functional', 'TotRmsAbvGrd', 'MSSubClass', 'GarageArea', 'LandSlope', 'GarageYrBlt', 'LotArea'...replaces', 'HeatingQC', 'BedroomAbvGr', 'MasVnrArea', 'LotFrontage', 'ModFunctional', 'Utilities'])]),\n",
       " 'impute_nums': SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "        strategy='median', verbose=0),\n",
       " 'scale_nums': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'other_nums__n_jobs': None,\n",
       " 'other_nums__remainder': 'drop',\n",
       " 'other_nums__sparse_threshold': 0.3,\n",
       " 'other_nums__transformer_weights': None,\n",
       " 'other_nums__transformers': [('impute_other',\n",
       "   SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='median', verbose=0),\n",
       "   ['LotShape',\n",
       "    'PoolArea',\n",
       "    'MiscVal',\n",
       "    'YrSold',\n",
       "    'WoodDeckSF',\n",
       "    'PavedDrive',\n",
       "    'Functional',\n",
       "    'TotRmsAbvGrd',\n",
       "    'MSSubClass',\n",
       "    'GarageArea',\n",
       "    'LandSlope',\n",
       "    'GarageYrBlt',\n",
       "    'LotArea',\n",
       "    'BsmtFinSF1',\n",
       "    'YearBuilt',\n",
       "    'SaleCondition',\n",
       "    'BsmtUnfSF',\n",
       "    'BsmtFinSF2',\n",
       "    'ModKitchenQual',\n",
       "    'Street',\n",
       "    'YearRemodAdd',\n",
       "    'LowQualFinSF',\n",
       "    'ModExterCond',\n",
       "    'ModExterQual',\n",
       "    'GarageCars',\n",
       "    'ModHeatingQC',\n",
       "    'Fireplaces',\n",
       "    'HeatingQC',\n",
       "    'BedroomAbvGr',\n",
       "    'MasVnrArea',\n",
       "    'LotFrontage',\n",
       "    'ModFunctional',\n",
       "    'Utilities']),\n",
       "  ('scale_other',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "   ['LotShape',\n",
       "    'PoolArea',\n",
       "    'MiscVal',\n",
       "    'YrSold',\n",
       "    'WoodDeckSF',\n",
       "    'PavedDrive',\n",
       "    'Functional',\n",
       "    'TotRmsAbvGrd',\n",
       "    'MSSubClass',\n",
       "    'GarageArea',\n",
       "    'LandSlope',\n",
       "    'GarageYrBlt',\n",
       "    'LotArea',\n",
       "    'BsmtFinSF1',\n",
       "    'YearBuilt',\n",
       "    'SaleCondition',\n",
       "    'BsmtUnfSF',\n",
       "    'BsmtFinSF2',\n",
       "    'ModKitchenQual',\n",
       "    'Street',\n",
       "    'YearRemodAdd',\n",
       "    'LowQualFinSF',\n",
       "    'ModExterCond',\n",
       "    'ModExterQual',\n",
       "    'GarageCars',\n",
       "    'ModHeatingQC',\n",
       "    'Fireplaces',\n",
       "    'HeatingQC',\n",
       "    'BedroomAbvGr',\n",
       "    'MasVnrArea',\n",
       "    'LotFrontage',\n",
       "    'ModFunctional',\n",
       "    'Utilities'])],\n",
       " 'other_nums__impute_other': SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "        strategy='median', verbose=0),\n",
       " 'other_nums__scale_other': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'other_nums__impute_other__copy': True,\n",
       " 'other_nums__impute_other__fill_value': None,\n",
       " 'other_nums__impute_other__missing_values': nan,\n",
       " 'other_nums__impute_other__strategy': 'median',\n",
       " 'other_nums__impute_other__verbose': 0,\n",
       " 'other_nums__scale_other__copy': True,\n",
       " 'other_nums__scale_other__with_mean': True,\n",
       " 'other_nums__scale_other__with_std': True,\n",
       " 'impute_nums__copy': True,\n",
       " 'impute_nums__fill_value': None,\n",
       " 'impute_nums__missing_values': nan,\n",
       " 'impute_nums__strategy': 'median',\n",
       " 'impute_nums__verbose': 0,\n",
       " 'scale_nums__copy': True,\n",
       " 'scale_nums__with_mean': True,\n",
       " 'scale_nums__with_std': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVR Names\n",
    "# Find the one-hot-encodings\n",
    "svr_ohe = svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[2][1].named_steps['encode'].get_feature_names().tolist()\n",
    "# Engineered features\n",
    "svr_eng_feat = svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[0][1].named_steps['feat_eng'].get_feature_names()\n",
    "# Other numeric? \n",
    "svr_other_num = svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[3][1].get_params()['transformers'][0][2]\n",
    "# but how to get the missing ... stuff? \n",
    "\n",
    "svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[1][1].get_params()\n",
    "\n",
    "#a = svr_ohe + svr_eng_feat + svr_other_num\n",
    "#len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF Names\n",
    "# One hot encodings\n",
    "rf_ohe = svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[2][1].named_steps['encode'].get_feature_names().tolist()\n",
    "# Engineered features\n",
    "rf_eng_feat = rf_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[0][1].named_steps['feat_eng'].get_feature_names()\n",
    "# Other numeric?\n",
    "rf_other_num = rf_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[3][1].get_params()['transformers'][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_jobs': None,\n",
       " 'remainder': 'drop',\n",
       " 'sparse_threshold': 0.3,\n",
       " 'transformer_weights': None,\n",
       " 'transformers': [('impute_other',\n",
       "   SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='median', verbose=0),\n",
       "   ['LotShape',\n",
       "    'PoolArea',\n",
       "    'MiscVal',\n",
       "    'YrSold',\n",
       "    'WoodDeckSF',\n",
       "    'PavedDrive',\n",
       "    'Functional',\n",
       "    'TotRmsAbvGrd',\n",
       "    'MSSubClass',\n",
       "    'GarageArea',\n",
       "    'LandSlope',\n",
       "    'GarageYrBlt',\n",
       "    'LotArea',\n",
       "    'BsmtFinSF1',\n",
       "    'YearBuilt',\n",
       "    'SaleCondition',\n",
       "    'BsmtUnfSF',\n",
       "    'BsmtFinSF2',\n",
       "    'ModKitchenQual',\n",
       "    'Street',\n",
       "    'YearRemodAdd',\n",
       "    'LowQualFinSF',\n",
       "    'ModExterCond',\n",
       "    'ModExterQual',\n",
       "    'GarageCars',\n",
       "    'ModHeatingQC',\n",
       "    'Fireplaces',\n",
       "    'HeatingQC',\n",
       "    'BedroomAbvGr',\n",
       "    'MasVnrArea',\n",
       "    'LotFrontage',\n",
       "    'ModFunctional',\n",
       "    'Utilities']),\n",
       "  ('scale_other',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "   ['LotShape',\n",
       "    'PoolArea',\n",
       "    'MiscVal',\n",
       "    'YrSold',\n",
       "    'WoodDeckSF',\n",
       "    'PavedDrive',\n",
       "    'Functional',\n",
       "    'TotRmsAbvGrd',\n",
       "    'MSSubClass',\n",
       "    'GarageArea',\n",
       "    'LandSlope',\n",
       "    'GarageYrBlt',\n",
       "    'LotArea',\n",
       "    'BsmtFinSF1',\n",
       "    'YearBuilt',\n",
       "    'SaleCondition',\n",
       "    'BsmtUnfSF',\n",
       "    'BsmtFinSF2',\n",
       "    'ModKitchenQual',\n",
       "    'Street',\n",
       "    'YearRemodAdd',\n",
       "    'LowQualFinSF',\n",
       "    'ModExterCond',\n",
       "    'ModExterQual',\n",
       "    'GarageCars',\n",
       "    'ModHeatingQC',\n",
       "    'Fireplaces',\n",
       "    'HeatingQC',\n",
       "    'BedroomAbvGr',\n",
       "    'MasVnrArea',\n",
       "    'LotFrontage',\n",
       "    'ModFunctional',\n",
       "    'Utilities'])],\n",
       " 'impute_other': SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "        strategy='median', verbose=0),\n",
       " 'scale_other': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'impute_other__copy': True,\n",
       " 'impute_other__fill_value': None,\n",
       " 'impute_other__missing_values': nan,\n",
       " 'impute_other__strategy': 'median',\n",
       " 'impute_other__verbose': 0,\n",
       " 'scale_other__copy': True,\n",
       " 'scale_other__with_mean': True,\n",
       " 'scale_other__with_std': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing numeric\n",
    "#svr_missing_num = \n",
    "svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[1][1].named_steps['other_nums'].get_params()\n",
    "#rf_missing_num = rf_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[3][1].get_params()['transformers'][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BsmtFinType1',\n",
       " 'Condition1',\n",
       " 'GarageQual',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'Fence',\n",
       " 'BsmtCond',\n",
       " 'Heating',\n",
       " 'MoSold',\n",
       " 'Condition2',\n",
       " 'Neighborhood',\n",
       " 'BsmtExposure',\n",
       " 'CentralAir',\n",
       " 'Foundation',\n",
       " 'BsmtFinType2',\n",
       " 'BldgType',\n",
       " 'Exterior2nd',\n",
       " 'MSZoning',\n",
       " 'MasVnrType',\n",
       " 'RoofMatl',\n",
       " 'RoofStyle',\n",
       " 'Exterior1st',\n",
       " 'HouseStyle',\n",
       " 'PoolQC',\n",
       " 'BsmtQual',\n",
       " 'Electrical',\n",
       " 'GarageCond',\n",
       " 'GarageType',\n",
       " 'LotConfig',\n",
       " 'LandContour',\n",
       " 'Alley',\n",
       " 'FireplaceQu',\n",
       " 'GarageFinish']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing categorical\n",
    "svr_missing_cat = svr_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[4][1].get_params()['transformers'][0][2]\n",
    "rf_missing_cat = rf_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[4][1].get_params()['transformers'][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final column names\n",
    "svr_feature_names = feature_num + other_num_cols + svr_ohe\n",
    "rf_feature_names = feature_num + other_num_cols + rf_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Transform the Validation Set\n",
    "X_train_prepared = final_pipeline.fit_transform(X_train)\n",
    "X_val_transformed = final_pipeline.transform(X_val)\n",
    "#X_train_prepared.shape\n",
    "X_val_transformed.shape\n",
    "\n",
    "## Convert this into a pandas dataframe\n",
    "# X_val_df = pd.DataFrame(X_val_transformed)\n",
    "# X_val_df.columns = all_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Importance through Permutation\n",
    "perm = PermutationImportance(svr_model, random_state=42).fit(X_val_transformed, y_val)\n",
    "#eli5.show_weights(perm, feature_names = all_feature_names, top = 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cb1651541df46dc1b8c195e1f43868029a636f9"
   },
   "source": [
    "## Partial Dependency Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'ModHeatingQC'\n",
    "pdp_housing = pdp.pdp_isolate(\n",
    "    model=svr_model, \n",
    "    dataset=X_val_df, \n",
    "    model_features=all_feature_names, \n",
    "    feature=name\n",
    ")\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_housing, name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab7e10f246821fec13a00072f58e254f7f0fa9ef",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Names of Numeric features\n",
    "num_cols = hprObject.train._get_numeric_data().columns\n",
    "feature_name_list = list(num_cols)\n",
    "\n",
    "# Select numerical features\n",
    "num_train_df = hprObject.train[feature_name_list]\n",
    "\n",
    "# Numeric Pipeline\n",
    "numerical_pipeline = Pipeline([\n",
    "   # ('drop_columns', DropMissing(threshold_percent = 0.07)),\n",
    "    ('select_numeric', TypeSelector(np.number)),\n",
    "    ('impute_missing', SimpleImputer(strategy = \"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('select_features', SelectPercentile(mutual_info_regression, percentile=95))\n",
    "])\n",
    "\n",
    "# Run through pipeline\n",
    "num_train_np = numerical_pipeline.fit_transform(X = num_train_df, y = hprObject.price_labels)\n",
    "\n",
    "# Split \n",
    "X_train, X_val, y_train, y_val = train_test_split(num_train_np, hprObject.price_labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eab522ea26b0964f4c713a83294f815aa858d8f6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dataframe copy of X_Val\n",
    "X_val_df = pd.DataFrame(X_val)\n",
    "X_val_df.columns = feature_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63538c49ed8b92d2020bdd58a2ad9ed919b8376f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "rnd_search_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=10, verbose=2, random_state=42)\n",
    "rnd_search_cv.fit(X_train, y_train)\n",
    "\n",
    "# Fit with optimal Parameters\n",
    "svr_model = SVR(gamma = rnd_search_cv.best_params_[\"gamma\"], C = rnd_search_cv.best_params_[\"C\"])\n",
    "svr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b375fdee8ac70b0ff4e92a1f180303410607a31a"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6b5153176c13fae78c8c5442aa1e7b5a149862b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "perm = PermutationImportance(svr_model, random_state=1).fit(X_val, y_val)\n",
    "eli5.show_weights(perm, feature_names = feature_name_list, top = 58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2288c03cd91cad5113672541bb2f1f62cece70d2"
   },
   "source": [
    "## Partial Dependency Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c15c779691feee7f8ebef4f19972377466a67998",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a series of partial depedency plots\n",
    "name = 'ModHeatingQC'\n",
    "pdp_housing = pdp.pdp_isolate(model=svr_model, dataset=X_val_df, model_features=feature_name_list, feature=name)\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_housing, name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b047fa161a346ac989ad84770e4de4839adda7f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a series of partial depedency plots\n",
    "name='HeatingQC'\n",
    "pdp_housing = pdp.pdp_isolate(model=svr_model, dataset=X_val_df, model_features=feature_name_list, feature=name)\n",
    "\n",
    "# plot it\n",
    "pdp.pdp_plot(pdp_housing, name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "01f06f004590e2161b5d7b007aa0729120d8bfc4"
   },
   "source": [
    "## Fit Data with Model(s) & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee6fc950a2392225017325ac6c7f74315f34f9ea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train into train and validation sets\n",
    "TrainX, ValX, TrainY, ValY = train_test_split(hprObject.train, hprObject.price_labels, test_size = 0.2)\n",
    "\n",
    "# run full pipeline\n",
    "train_data = unify_pipeline.fit_transform(TrainX, TrainY)\n",
    "\n",
    "# Run SVR()\n",
    "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
    "svr_cv = RandomizedSearchCV(SVR(), param_distributions, n_iter=10, verbose=2, random_state=42)\n",
    "svr_cv.fit(train_data, TrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3578bddc55efb2328c74fd86c496f81815cfcc22",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svr_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70359137543b5cf4d4c2b45073a59e561068665c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run pipeline for validation data\n",
    "test_data = unify_pipeline.transform(ValX, ValY)\n",
    "\n",
    "# Generate predictions to compare between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc6c3f387566d9520c3424bc4429e0a89643a1a9"
   },
   "source": [
    "## Try Running Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a4478950f9140f6ae40675763a3ed9d77e8e3e00",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b8a118c394e7576aae81b2c85634b02b2932a1b"
   },
   "source": [
    "## Trying something different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c9ecbbc97b9bdf7475784500be1982f021cf4ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a041e93a9736cae6db4444249b1849f08302e934"
   },
   "source": [
    "## Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4fbf36d06564d7fa2ae9432ee19da07d3ffeeaa9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission\n",
    "y_pred = rnd_search_cv.best_estimator_.predict(train_prepared)\n",
    "mse = mean_squared_error(price_labels, y_pred)\n",
    "np.exp(np.sqrt(mse))\n",
    "\n",
    "fitted_model = SVR().fit(X=prepared_train, y=hprObject.price_labels)\n",
    "predictions = fitted_model.predict(prepared_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
