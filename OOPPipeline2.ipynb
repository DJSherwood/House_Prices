{"cells":[{"metadata":{"_uuid":"7fad15a600d8a4b8a0e8a23fef765b8b578b0596"},"cell_type":"markdown","source":"# Introduction\nI had previously written a short kernel to practice Python. My \"native language\" is R, but the benefits of using Python are too great to ignore. In this notebook, I revist the same dataset but attempt several additional techniques, including: \n1. Pre-process with object-oriented programming\n2. Create Pipeline\n3. Use partial dependency plots\n4. running multiple aglorithms through a pipeline\n\nThe individual elements could be the subject af a kernel all to themselves, but I am choosing to make each occupy a section within this Kernel. I hope this helps you on your python journey! "},{"metadata":{"_uuid":"20a145f3146cd2976f0ab5a8c58ac148170b9710"},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import Libraries\nimport pandas as pd\nimport numpy as np\nfrom subprocess import check_output\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.decomposition import PCA, SparsePCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.impute import MissingIndicator\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom scipy.stats import reciprocal, uniform\nfrom pdpbox import pdp, info_plots\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport functools","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c27632dd1c175006c86049bba665ae304d5068d"},"cell_type":"markdown","source":"# Dictionaries"},{"metadata":{"_uuid":"2c9977d2d8d7ae50e2a5129cf3f368e87e6cb6f9"},"cell_type":"markdown","source":"Below is a (nested?) dictionary which contains specific values for each column. This was initially performed by another user on Kaggle -- if someone happens to know who made these dicionaries initially then I will edit this notebook and provide proper attribution.  My contribution was to coalesce all of the user's individual dictionaries into one. "},{"metadata":{"trusted":true,"_uuid":"de20ffb3ea9c86109148b3b202ce0e48f516436f"},"cell_type":"code","source":"replacement_dict = {\"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\", 7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"},\n            \"SaleCondition\" : {\"Abnorml\" : 0, \"Alloca\" : 0, \"AdjLand\" : 0, \"Family\" : 0, \"Normal\" : 0, \"Partial\" : 1},\n            \"ExterCond\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n            \"ExterQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n            \"Functional\" : {\"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n            \"HeatingQC\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n            \"KitchenQual\" : {\"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n            \"LandSlope\" : {\"Sev\" : 1, \"Mod\" : 2, \"Gtl\" : 3},\n            \"LotShape\" : {\"IR3\" : 1, \"IR2\" : 2, \"IR1\" : 3, \"Reg\" : 4},\n            \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n            \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n            \"Utilities\" : {\"ELO\" : 1, \"NoSeWa\" : 2, \"NoSewr\" : 3, \"AllPub\" : 4},\n            \"OverallQual\" : {1 : 1, 2 : 1, 3 : 1, # bad\n                           4 : 2, 5 : 2, 6 : 2, # average\n                           7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                          },\n            \"OverallCond\" : {1 : 1, 2 : 1, 3 : 1, # bad\n                                      4 : 2, 5 : 2, 6 : 2, # average\n                                      7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                     },\n    \"ModExterCond\" : {1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  },\n    \"ModExterQual\" : {1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  },\n    \"ModFunctional\" : {1 : 1, 2 : 1, # bad\n                                                     3 : 2, 4 : 2, # major\n                                                     5 : 3, 6 : 3, 7 : 3, # minor\n                                                     8 : 4 # typical\n                                                    },\n    \"ModKitchenQual\" : {1 : 1, # bad\n                                                       2 : 1, 3 : 1, # average\n                                                       4 : 2, 5 : 2 # good\n                                                      },\n    \"ModHeatingQC\" : {1 : 1, # bad\n                                                   2 : 1, 3 : 1, # average\n                                                   4 : 2, 5 : 2 # good\n                                                  }   \n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1b1c6122c57550ddaad078e394524e7c8bf34a0"},"cell_type":"markdown","source":"# Pre-process with Object Oriented Programming"},{"metadata":{"_uuid":"319646cf9658217dd5c3a507168835e2451d7be4"},"cell_type":"markdown","source":"I have learned that there are many benefits to using OOP with Python. It makes code more readable, reproducible, testable, etc. For this section, I create a python class specifically for this competition to handle the \"pre-processing\" of the data. What I mean by \"pre-processing\" is making the training and testing sets equivalent in form. This class contains functions to: \n1. Load the training and testing data\n2. Generate a \"submission\" dataframe\n3. Use the above dictionary to replace vlalues\n4. Log transforming the response\n5. Removing categories that do not show up in Test (to allow for one-hot-encoding)"},{"metadata":{"trusted":true,"_uuid":"e797274dd9e4df5c89f26f4c6614917a15308b4f"},"cell_type":"code","source":"# Define Class\nclass HousingPricesRegression():\n    # class initialization\n    def __init__(self, train_path, test_path):\n        self.train = pd.read_csv(train_path)\n        self.test = pd.read_csv(test_path)\n        self.submission = pd.DataFrame()\n        self.percent = 0.07\n        self.keep_columns = []\n\n    def gen_submission_file(self, id_col):\n        self.submission[id_col] = self.test[id_col]\n        self.test.drop([id_col], axis = 1, inplace=True)\n        self.train.drop([id_col], axis = 1, inplace=True)\n        \n    # replace information within columns\n    def replace_values(self, replace_dict):\n        # Find name (top level key)\n        key_name = str(*replace_dict)\n        true_index = np.where(self.train.columns.isin([key_name]))\n        col_name = list(self.train.columns[true_index])\n        if len(col_name) == 0:\n            # Option 1: Dictionary refers to a key that doesn't exist. Create one!\n            orig_name = key_name[3:]\n            self.train[key_name] = self.train[orig_name].map(replace_dict[key_name])\n            self.test[key_name] = self.test[orig_name].map(replace_dict[key_name])\n        else:\n            # Option 2: Dictionary refers to a key that does exist. Modify! \n            # Take 'ModExterCond' and find the original (\"ExterCond\")\n            self.train[key_name] = self.train[key_name].map(replace_dict[key_name])\n            self.test[key_name] = self.test[key_name].map(replace_dict[key_name])\n            \n    # Take Logarithm of Response\n    def create_response(self, response):\n        self.price_labels = np.log(self.train[response].copy() + 1)\n        # drop original to avoid confusion\n        self.train.drop([response], axis=1, inplace = True)  \n        \n    def drop_missing(self, threshold_percent):\n        self.percent = ( self.train.isnull().sum() / self.train.isnull().count() ).sort_values(ascending=False)\n        ## make list of columns to be dropped\n        self.keep_columns = list(self.percent[self.percent < threshold_percent].index)\n        ## drop columns\n        self.train = self.train[self.keep_columns]\n        self.test = self.test[self.keep_columns]\n        \n    # Remove categories \n    def remove_categories(self, cat_cols):\n        for i in cat_cols:\n            trn = self.train[i].astype('category')\n            trn = trn.cat.categories\n            tst = self.test[i].astype('category')\n            tst = tst.cat.categories\n            # Find that which is in test which is not in train\n            unique_values_train = list(set(trn) - set(tst))\n            # Check \n            # If no difference, print\n            if len(unique_values_train)==0:\n                print(\"No Differnence for {}\".format(i))\n            else:\n                # If there is a differnce, change to NA in test for later imputation\n                for j in unique_values_train:\n                    to_replace_index = self.train.loc[self.train[i]==j,i].index\n                    self.train.loc[to_replace_index,i] = float('NaN')\n                    self.train[i] = self.train[i].cat.remove_categories(j)\n                    print(\"{} removed from {} in train\".format(j,i))\n                    \n    # Set the category type \n    def make_category(self, cat_cols):\n        self.train[cat_cols] = self.train[cat_cols].astype('category')\n        self.test[cat_cols] = self.test[cat_cols].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c7cd3b831c86b1d5bc7d462ff4667aa396ad86b"},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true,"_uuid":"c95568a9daaf3929f3a01acc609126a33224e3d9"},"cell_type":"code","source":"# Define Paths\nfile_path = '../input/'\ntrain_path = str(file_path) + str('train.csv')\ntest_path = str(file_path) + str('test.csv')\nsubmission_path = str(file_path) + str()\n\n# Instantiate model object\nhprObject = HousingPricesRegression(train_path, test_path)\n\n# Generate submission file\nhprObject.gen_submission_file(id_col='Id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Response\nThis creates a single column dataframe called `price_labels` that is a copy of that in train, except log-transformed. The corresponding column in the train dataframe is also dropped. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# This takes the log of the sales price\nhprObject.create_response(response=\"SalePrice\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Drop Missing\nAll columns missing more than \"threshold percent\" are dropped. Also shown is a custom transformer to accomplish this."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Custom transformer not used...\n# class DropMissing(BaseEstimator, TransformerMixin):\n#    def __init__(self, threshold_percent):\n#        self.keep_columns = None\n#        self.threshold_percent = threshold_percent\n#    def fit(self, X, y=None):\n#        return self\n#    def transform(self, X):\n#        ## calculate percent missing\n#        percent = ( X.isnull().sum() / X.isnull().count() ).sort_values(ascending=False)\n#        ## make list of columns to be dropped\n#        self.keep_columns = list(percent[percent < self.threshold_percent].index)\n#        X = X[self.keep_columns]\n#        return X\n#    def fit_transform(self, X, y=None):\n#        return self.fit(X,y).transform(X)\n\n## Drop colums which have too many missing rows\nhprObject.drop_missing(threshold_percent=0.06)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Call Replacement Method\nLoop through the dictionary replacing the values listed therein for each column."},{"metadata":{"trusted":true,"_uuid":"dee1661cdf3ed6fb93269b0466dc33f42f5338b6"},"cell_type":"code","source":"# Replace features - multiple columns\nfor key, values in replacement_dict.items():\n    temp_dict = {}\n    temp_dict[key] = replacement_dict[key] \n    hprObject.replace_values(temp_dict)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3dd451a99239b17fd5ec80168b44975df67a242"},"cell_type":"markdown","source":"### Set Category and Numeric Columns"},{"metadata":{"trusted":true,"_uuid":"c9550b2e545818a66b43ee5087ab03906b379d52"},"cell_type":"code","source":"## Create list of numerical and categorical attributes\nnum_cols = hprObject.test._get_numeric_data().columns\ncat_cols = list(set(hprObject.test.columns) - set(num_cols))\nnum_cols = list(num_cols)\n\n## Need to move this to a class method or something\nhprObject.make_category(cat_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pipeline"},{"metadata":{},"cell_type":"markdown","source":"### Pipelines Finally\nAnd now we are finally able to create a pipeline. There are so many powerful scripts / notebooks on Kaggle, and yet so few examples as to how to use the pipeline library. I now going to put the HousingRegressionPrices class aside and focus on building a pipeline. I found this process quite challenging because I am quite new to python. I am pleased with the result and I encourage you to take it and make it even better! \n\nThe key to underatanding this pipeline is that not all columns go through the pipeline \"equally\". There are essentially three groups of columns: \n\n1. Numeric columns which are used to create new features\n2. Numeric columns which are not used to create new features\n3. Categorical columns which are one-hot-encoded\n\nThese 3 groups of columns are bound back together horizontally by \"Feature Union\". \n\n#### Group 1: Numeric Columns & Feature Creation\nIn the first edition of [*Hands-On Machine Learning with Scikit-Learn and TensorFlow*](https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B06XNKV5TS/ref=sr_1_4?crid=1D12AT1KWITI1&keywords=hands+on+machine+learning+with+scikit-learn+and+tensorflow&qid=1555695123&s=gateway&sprefix=hands+on+machine+lear%2Caps%2C156&sr=8-4), Aurelien Geron explained how to create custom transformers which work with pandas dataframes. Recently, however, a new class has been introduced in Sklearn called [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) which effectively does this for you. I feed in speciifc columns *by name* and have PolynomialFeatures create interactions between these features. If you do not set 'remainder' to 'drop' then the other columns will be passed through this transformer in addition to the columns you explicitly speciifed. This could be confusing later, so I definitely advocate the use of 'drop'. Imputation and StandardScaleing is also performed. See 'step1' for the pipeline. \n\n#### Group 2: Other Numeric Columns\nSince I've elected to 'drop' the non-named numeric columns, I need to gerate another set of transformers which works on them. See 'step2' for the pipeline. I also create a missing indicator matrix so that my modeling method can specifically learn which values were imputed. \n\n#### Group 3: Categorical\nI have the categorical data go through its own series of steps, first imputing by \"most_frequent\" and then converting the data into a one-hot-encoding. Again I create amissing indicator matrix so that imputed values can be learned. \n\nAnd here is the pipeline in all its glory. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Column Names ##\n# These were troublesome\n# kitchen_col = ['KitchenAbvGr', 'KitchenQual']\n# add_area = ['GrLivArea','TotalBsmtSF']\n# count_bath = ['BsmtFullBath','FullBath','BsmtHalfBath','HalfBath']\n# Using these:\ngrade_col = ['OverallQual', 'OverallCond']\nexter_cond = ['ExterQual','ExterCond']\nadd_floor = ['1stFlrSF', '2ndFlrSF']\nadd_porch = ['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch']\n\n#origFeat = grade_col + exter_cond + add_floor + add_porch \n\nfeat_eng_names = grade_col + ['OverallTotal'] + exter_cond + ['ExterTotal'] + \\\nadd_floor + ['FlrSFTotal'] + add_porch + ['UnionPorch'] + ['ModPorch1'] + ['ModPorch2'] + ['ModPorch3'] + ['ModPorch4'] + ['ModPorch5'] \n\nother_num_cols = list(set(num_cols) - set(feat_eng_names))\n\n## Actually, move the problem children 'multi_kitchen', 'add_total_SF', 'count_baths' to the 'other numeric' group. \n## They will be imputed with all the others, and feature engineering will be performed on the data without NAs\n## And that should be perfect! \n\n## Step 1: Feature Engineering ##\nfeature_engineering = ColumnTransformer(\n    transformers = [\n        ('multi_grade', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), grade_col),\n        ('multi_exter', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), exter_cond),\n        ('add_floor_SF', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), add_floor),\n        ('add_porch_SF', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False), add_porch),\n    ],\n    remainder='drop'\n)\n\nstep1 = Pipeline([\n    ('feat_eng', feature_engineering),\n    ('impute_feats', SimpleImputer(strategy=\"mean\", copy=False)),\n    ('scale_feats', StandardScaler())\n])\n\n## Step 2: Other Numeric Columns ##\nother_numerical = ColumnTransformer(\n    transformers = [\n        ('impute_other', SimpleImputer(strategy=\"mean\", copy=False), other_num_cols),\n    ],\n    remainder='drop'\n)\n\nstep2 = Pipeline([\n    ('other_nums', other_numerical),\n    ('scale_other', StandardScaler())\n])\n\n## Step 3: Categorical Columns ## \ncategorical = ColumnTransformer(\n    transformers = [\n        ('impute_cats', SimpleImputer(strategy=\"most_frequent\", copy=False), cat_cols),\n    ],\n    remainder='drop'\n)\n\nstep3 = Pipeline([\n    ('categ', categorical),\n    ('encode', OneHotEncoder(handle_unknown='ignore'))\n])\n\n## Step 4: Missing indicators \nother_missing = ColumnTransformer(\n    transformers = [\n        ('other_missing', MissingIndicator(features='all'), other_num_cols)\n    ],\n    remainder='drop'\n)\n\ncategory_missing = ColumnTransformer(\n    transformers = [\n        ('cat_missing', MissingIndicator(features='all'), cat_cols)\n    ],\n    remainder='drop'\n)\n\n## Step 5: Unify ##     \nunify = FeatureUnion([\n    ('new_features', step1 ),\n    ('numeric_scale', step2), \n    ('categoric_encode', step3),\n    ('num_missing_indicator', other_missing),\n    ('cat_missing_indicator', category_missing)\n])\n\nfinal_pipeline = Pipeline([\n    ('finally', unify)\n])\n\n## Just checking\n#f = final_pipeline.fit_transform(hprObject.train)\n#type(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Parameters\n\nThe \"prepared\" data is now split (simply) into training / validation sets. The dataset for this competition is very small, so I was hesitant to make the test set much larger. \nI also specify a few parameters for both SVR() and RandomForestRegressor(). You'll see why the nested diciontary is necessary in a moment. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# split train into train and validation set\nX_train, X_val, y_train, y_val = train_test_split(hprObject.train, hprObject.price_labels, test_size = 0.2)\n\n# list names of regressors\nnames = [\n         \"Support-Vector Regressor\",\n         \"Random Forest Regressor\"\n        ]\n\nregressors = [\n    SVR(),\n    RandomForestRegressor()\n]\n\nparameters = [\n                  {\n                      'reg__C': (reciprocal(0.001, 0.1)), \n                      'reg__gamma': (uniform(1, 10))\n                  },\n                  {\n                      'reg__max_depth': (5,10,15)\n                  }\n             ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\nI wanted to have the ability to run multiple models on the same pipeline. Someone (I forget the link) posted some code on StackOverFlow; I've adapted it here. Essentially, a pipeline is appended within a for-loop with different regressors. The pipeline is fit with the training data, scored, and the model is saved in the 'model_list' dictionary for future use. I also use RandomizedGridSearch instead of ordinary GridSearch because...I'm cool :) ."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list = {}\nfor name, regressor, params in zip(names, regressors, parameters):\n    reg_pipe = Pipeline([\n        ('pipeline', final_pipeline),\n        ('reg', regressor)\n    ])\n    rs_reg = RandomizedSearchCV(reg_pipe, params, n_iter=10, verbose=2, random_state=42, scoring='neg_mean_squared_error')\n    regres = rs_reg.fit(X_train, y_train)\n    score = regres.score(X_val, y_val)\n    print(\"{} score: {}\".format(name, score))\n    model_list[name] = regres","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Best SVR Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list['Support-Vector Regressor'].best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Best RF Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list['Random Forest Regressor'].best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance / Partial Dependence\n\nI think that the RandomForestRegressor already has a feature importance method. Below, I attempt to generate feature importance and partial dependency plots for my Support-Vector Regressor. Something is not quite right with my model, because my features are all zero and the plots show a minimal effect. \n\nUseful tips: \n\n1. Navigate your pipeline using 'named_steps['name'].transformer_list. I was able to find the one-hot-encoded names this way\n2. pdpbox likes DataFrames\n3. Scipy.sparse_matrix can be converted to a dense array by .toarray()\n4. eli5 and pdpbox do not like pipelines"},{"metadata":{},"cell_type":"markdown","source":"### Generate Names"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Transform the Validation Set\nX_train_prepared = final_pipeline.fit_transform(X_train)\ny_train_values = y_train.values\n\n## ELI5 requires dense matrix\nX_val_prepared = final_pipeline.transform(X_val)\nX_val_prepared = X_val_prepared.toarray()\ny_val_values = y_val.values\n\nohe_names = reg_pipe.named_steps['pipeline'].named_steps['finally'].transformer_list[2][1].named_steps['encode'].get_feature_names().tolist()\nnum_missing_names = [ i + str('_missing') for i in other_num_cols ]\ncat_missing_names = cat_cols\ndata_names = feat_eng_names + other_num_cols + ohe_names + num_missing_names + cat_missing_names\n#data_names = feat_eng_names + other_num_cols + ohe_names","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Convert this into a pandas dataframe\nX_val_df = pd.DataFrame(data=X_val_prepared, columns=data_names, index=[i for i in range(0, 292)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit Estimator Outside of Pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Interestingly, SVR() doesn't seem to work very well. Perhaps I need to perform dimension reduction\n## on the training set\n#svr_model = SVR(gamma = model_list['Support-Vector Regressor'].best_params_[\"reg__gamma\"], \n#    C = model_list['Support-Vector Regressor'].best_params_[\"reg__C\"]).fit(X_train_prepared, y_train_values)\n\nrf_model = RandomForestRegressor(max_depth = model_list['Random Forest Regressor'].best_params_[\"reg__max_depth\"]).fit(X_train_prepared, y_train_values)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Importance"},{"metadata":{},"cell_type":"markdown","source":"The RandomForestRegressor() in sklearn has its own feature importance method (attribute?). I chose to use this because I wanted to examine the importance features from the SVM model. I must have drastically overfit or create a few too many features because all of the features have a score of 0 for my SVM. I am pleased with the RandomForest, however. \n\n'OverallQual(ity)' is the top feature followed by 'Gr(ound)Liv(ing)Area'. 'YearBuilt' is also in the top 10, which makes sense. "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Feature Importance through Permutation\nperm = PermutationImportance(rf_model, random_state=42).fit(X_val_prepared, y_val_values)\neli5.show_weights(perm, feature_names = data_names, top = 48)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cb1651541df46dc1b8c195e1f43868029a636f9"},"cell_type":"markdown","source":"## Partial Dependency Plots"},{"metadata":{},"cell_type":"markdown","source":"This is the no. 1 feature according to my \"feature importance\" score. The partial dependcy plot shows that there is a near linear relation between overall quality and sale price after a certain point. The interpretability of these graph is confounded somewhat because I chose to standardize my training data and log transformed the sales price data. I originally did this for the SVM's sake but a Random Forest does not require standardized data. \nI leave it to you to experiment with! "},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot of single feature\npdp_housing = pdp.pdp_isolate(\n    model=rf_model, \n    dataset=X_val_df, \n    model_features=X_val_df.columns,\n    feature='OverallQual'\n)\n\npdp.pdp_plot(pdp_housing, 'OverallQual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plot of single feature\npdp_housing = pdp.pdp_isolate(\n    model=rf_model, \n    dataset=X_val_df, \n    model_features=X_val_df.columns,\n    feature='YearBuilt'\n)\n\npdp.pdp_plot(pdp_housing, 'YearBuilt')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Adapted from Dan's Kaggle Notebook on Machine Learning\nfeatures_to_plot = ['OverallQual', 'GrLivArea']\ninter1  =  pdp.pdp_interact(model=rf_model, \n                            dataset=X_val_df, \n                            model_features=X_val_df.columns, \n                            features=features_to_plot)\n\n## This throws an error and then creates a plot anyway? \npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type='contour')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Fit\nI am choosing to use the Random Forest model because its final score in my cross-validation scheme was much lower than than the SVM (-0.019 vs -0.148). Granted, I did not tune my hyperparameters *very well* and there are definitely more hyperparameters to choose from. I also think that I may need to perform some dimension reduction or eliminate the \"missing indicators\" for the SVM; when I tried to generate predictions from the SVM all that it predicted was the same value over and over. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Last pipe - using \"tuned\" hyperparameters for Random Forest (yes, much more tuning could be done!)\nalldata_pipe = Pipeline([\n        ('pipeline', final_pipeline),\n        ('select', VarianceThreshold(0.15)),\n        ('rf', RandomForestRegressor(\n            max_depth=model_list['Random Forest Regressor'].best_params_[\"reg__max_depth\"]\n        ))\n        #('svm', SVR(\n        #    gamma=model_list['Support-Vector Regressor'].best_params_['reg__gamma'],\n        #    C=model_list['Support-Vector Regressor'].best_params_['reg__C']\n        #))\n    ])\n\n# The final estimator, RandomForestRegressor(), does not have a .fit_transform method\nfinal_model = alldata_pipe.fit(hprObject.train, hprObject.price_labels.values)\n\n# And ta da! We have our predictions\nlog_predictions = final_model.predict(hprObject.test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a041e93a9736cae6db4444249b1849f08302e934"},"cell_type":"markdown","source":"## Generate Submission File"},{"metadata":{},"cell_type":"markdown","source":"Here I convert back from log+1 dollars back to regular dollars. "},{"metadata":{"trusted":true,"_uuid":"4fbf36d06564d7fa2ae9432ee19da07d3ffeeaa9"},"cell_type":"code","source":"predictions = (np.exp(log_predictions) - 1)\npredictions","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission Complete! "},{"metadata":{"trusted":true},"cell_type":"code","source":"hprObject.submission['SalePrice'] = pd.Series(predictions, index=hprObject.submission.index)\nhprObject.submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}